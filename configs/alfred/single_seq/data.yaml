_target_: data.language_behavior.ALFREDLanguageBehaviorDataModule
data_conf: 
  env_name: alfred
  data_dir: /misery/anthony/alfred_orig_lmdb_2.1.0
  modalities:
    # - behavior
    - paired
    # - language
    
  paired_dataset_cls: # config for the dataset
    _target_: data.alfred.ALFREDTrajectoryDataset
    hparams:
      load_frac_done: True
      load_lang: True
      decoder_model_cls: gpt2
      subseq_len: 10
      data_dir: ${data_conf.data_dir} 
      partition: train
      add_lang_before_state: False
      chunk_size: 512
      debug: False
      return_conditioned: True
      input_format: v1
  
  behavior_dataset_cls: 
    _target_: data.alfred.ALFREDTrajectoryDataset
    hparams: 
      load_frac_done: True
      load_lang: False
      data_dir: ${data_conf.data_dir} 
      partition: train
      discretize_actions: False
      num_bins: 256
      chunk_size: ${data_conf.paired_dataset_cls.hparams.chunk_size}

  language_datasets: 
    - data.language.LanguageDataset

  language_dataset_cls: # target is provided in the code
    hparams: 
      data_dir: ${data_conf.data_dir} 
      vocab_file: kitchen.vocab
      mapping_file: text_to_emb.pkl
      annotation_file: annotations.json
      language_skills_file: skills_small.txt
      chunk_size: ${data_conf.paired_dataset_cls.hparams.chunk_size}
      decoder_model_cls: ${data_conf.paired_dataset_cls.hparams.decoder_model_cls}
      
      # wikihow specific
      wikihow_data_dir: /data/anthony/wikihow 
      wikihow_data_file: combined_text.txt

  dataloader_cls:
    _target_: data.sampler.RepeatedDataLoader
    n_repeat: 5
    num_workers: 4
    batch_size: 6